<style>

.small-code pre code {
  font-size: 0.5em;
}
</style>

Data Science Capstone Project
========================================================
author: Nick Murray 
date: 19 April 2018
autosize: false
font-import: https://fonts.googleapis.com/css?family=Open+Sans
font-family: 'Open Sans', sans-serif;
transition: rotate
class: small-code

In some environments and situations, it is difficult to enter text using a keyboard:

- IDEs, where you need to pick a variable or API name from a long list
- Smartphones, where text entry is difficult due to size or layout of keyboards

This app shows a partial solution to the word prediction problem: predicting the next word from a pre-defined and pre-processed corpus.

Data processing outline
========================================================
class: small-code
title:false

Data processing outline

- Prediction uses English twitter/news/blog corpora from:

	https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip

- For each twitter/news/blog corpus

 -- change character encoding from UTF-8 to ASCII
 -- remove digits, puncutation, control characters, spaces at start of line, blanks, common English profanity
 
- After merging each corpus, create full (4M lines) and small (400klines) training (70%) and test (30%) sets
- Create 1-4 ngrams using R **TidyText** package 
- Use data.table (DT) as a data store
- Split ngrams into individual words & index on each word
- No special edge-cases considered

Design Decisions
========================================================
class: small-code
title:false

Design Decisions

- Predictions are based on maximum likelihood with Stupid Backoff
- Ngram broken into, and indexed on, individual tokens - approximately 0.02 seconds per lookup
- 1-5gram database size approx 800MB, too large for ShinyApps; 1-4gram database fits within a ShinyApps "large" instance (1GB)
- Tried mapping unigrams to integers and using integers in 2-5 grams: 
  - Approx 50% size reduction in storage 
  - But data.table access via integers approx 50 times slower (0.1 s vs 0.02s)   



App Design
==========================================
class: small-code
title:false

App Design

- The app is located at: https://flutable.shinyapps.io/NMDS10Capstone2/
- Data loading takes 30 seconds or so

![app layout](app.png)

How to use
- Enter a phrase into the text box
- App detects last 1-4 grams user types, predicted word is last word of (n+1)-gram (maximum likelihood)
- Single column layout.
- Expose predicted word from each ngram; final prediction is predicted word from highest-order ngram
- Final upload size approx 86 MB compressed



Performance & Future work
========================================================
class: small-code
title: false

Performance 

- Measured using benchmark https://github.com/hfoffani/dsci-benchmark
- Accuracy about 12% using 10% of corpus only.

Future work
- Migrate ngram data.table to integer lookup tables (as previously) & solve the indexing problem
- Re-implement in python as a learning exercise 
- Add the ability to scan additional corpora
- Better profanity detection
- Better unknown words handling

